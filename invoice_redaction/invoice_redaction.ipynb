{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilingual Invoice OCR & PII Redaction\n",
    "Notebook implementing invoice scanning, OCR and PII redaction pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from pdf2image import convert_from_path\n",
    "from langdetect import detect, DetectorFactory\n",
    "\n",
    "DetectorFactory.seed = 42\n",
    "\n",
    "INPUT_GLOB = 'path/to/folder/**/*'\n",
    "SUPPORTED_EXTS = {'.pdf', '.jpg', '.jpeg', '.png', '.tiff', '.tif'}\n",
    "DPI = 300\n",
    "MAX_PAGES = 200\n",
    "\n",
    "OUT_IMG_DIR = Path('out/redacted_images')\n",
    "OUT_PDF_DIR = Path('out/redacted_pdf')\n",
    "REPORT_PATH = Path('out/pii_report.jsonl')\n",
    "for p in [OUT_IMG_DIR, OUT_PDF_DIR, REPORT_PATH.parent]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "def discover_files(pattern: str) -> List[Path]:\n",
    "    return [\n",
    "        Path(p)\n",
    "        for p in glob.glob(pattern, recursive=True)\n",
    "        if Path(p).suffix.lower() in SUPPORTED_EXTS\n",
    "    ]\n",
    "\n",
    "\n",
    "def pdf_to_images(pdf_path: Path, dpi: int = DPI, max_pages: int = MAX_PAGES):\n",
    "    return convert_from_path(str(pdf_path), dpi=dpi, first_page=1, last_page=max_pages)\n",
    "\n",
    "\n",
    "def load_images(path: Path, dpi: int = DPI, max_pages: int = MAX_PAGES) -> List[Image.Image]:\n",
    "    if path.suffix.lower() == '.pdf':\n",
    "        return pdf_to_images(path, dpi=dpi, max_pages=max_pages)\n",
    "    return [Image.open(path).convert('RGB')]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img: Image.Image) -> Image.Image:\n",
    "    arr = np.array(img)\n",
    "    gray = cv2.cvtColor(arr, cv2.COLOR_BGR2GRAY)\n",
    "    denoised = cv2.fastNlMeansDenoising(gray, h=10)\n",
    "    blurred = cv2.GaussianBlur(denoised, (3, 3), 0)\n",
    "    return Image.fromarray(blurred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04_layout_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from paddleocr import PaddleOCR\n",
    "\n",
    "USE_GPU = os.environ.get('USE_GPU', 'true').lower() == 'true'\n",
    "paddle = PaddleOCR(lang='en', use_gpu=USE_GPU, show_log=False)\n",
    "\n",
    "\n",
    "def run_ocr(img: Image.Image) -> List[Dict[str, object]]:\n",
    "    result = paddle.ocr(np.array(img), cls=True) or []\n",
    "    lines: List[Dict[str, object]] = []\n",
    "    for line in (result[0] if result else []):\n",
    "        quad, (text, conf) = line\n",
    "        lines.append({'bbox_quad': quad, 'text': text, 'conf': float(conf)})\n",
    "    return lines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05_language_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG_HINTS = ['en', 'hi', 'mr', 'ta', 'ru', 'pl']\n",
    "\n",
    "\n",
    "def detect_language(text: str) -> str:\n",
    "    if not text.strip():\n",
    "        return 'en'\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except Exception:\n",
    "        return 'en'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06_pii_detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMAIL_REGEX = re.compile(r'(?i)[A-Z0-9._%+-]+@[A-Z0-9.-]+\\.[A-Z]{2,}')\n",
    "PHONE_REGEX = re.compile(r'(?:\\+?91[-\\s]?)?[6-9]\\d{9}')\n",
    "\n",
    "\n",
    "def find_regex_pii(text: str) -> List[Dict[str, object]]:\n",
    "    hits = []\n",
    "    for match in EMAIL_REGEX.finditer(text):\n",
    "        hits.append({'type': 'EMAIL', 'text': match.group(), 'span': match.span()})\n",
    "    for match in PHONE_REGEX.finditer(text):\n",
    "        hits.append({'type': 'PHONE', 'text': match.group(), 'span': match.span()})\n",
    "    return hits\n",
    "\n",
    "\n",
    "def bbox_from_quad(quad: List[List[float]]) -> Tuple[int, int, int, int]:\n",
    "    xs = [pt[0] for pt in quad]\n",
    "    ys = [pt[1] for pt in quad]\n",
    "    return int(min(xs)), int(min(ys)), int(max(xs)), int(max(ys))\n",
    "\n",
    "\n",
    "def collect_pii(lines: List[Dict[str, object]]):\n",
    "    detections = []\n",
    "    boxes = []\n",
    "    for line in lines:\n",
    "        hits = find_regex_pii(line['text'])\n",
    "        if not hits:\n",
    "            continue\n",
    "        box = bbox_from_quad(line['bbox_quad'])\n",
    "        boxes.append(box)\n",
    "        for hit in hits:\n",
    "            detections.append({\n",
    "                'type': hit['type'],\n",
    "                'text_sample': hit['text'],\n",
    "                'bbox_xyxy': list(box),\n",
    "                'confidence': line['conf'],\n",
    "                'mask_applied': True,\n",
    "            })\n",
    "    return detections, boxes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07_redact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_redactions(img: Image.Image, boxes, color=(0, 0, 0)):\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for (x1, y1, x2, y2) in boxes:\n",
    "        draw.rectangle([x1, y1, x2, y2], fill=color)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_sha256(path: Path) -> str:\n",
    "    hasher = hashlib.sha256()\n",
    "    with path.open('rb') as f:\n",
    "        for chunk in iter(lambda: f.read(8192), b''):\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "\n",
    "def save_page(img: Image.Image, base: Path, page_num: int):\n",
    "    out = OUT_IMG_DIR / f'{base.stem}_{page_num:03d}.png'\n",
    "    img.save(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "def append_report(entry: dict):\n",
    "    with REPORT_PATH.open('a', encoding='utf8') as f:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09_qc_dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def show_side_by_side(original: Image.Image, redacted: Image.Image):\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title('Original')\n",
    "    axes[1].imshow(redacted)\n",
    "    axes[1].set_title('Redacted')\n",
    "    for ax in axes:\n",
    "        ax.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10_batch_runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def process_all(pattern=INPUT_GLOB, dpi: int = DPI, max_pages: int = MAX_PAGES):\n",
    "    files = discover_files(pattern)\n",
    "    if not files:\n",
    "        print(f'No files found for pattern: {pattern}')\n",
    "        return\n",
    "    for file in tqdm(files):\n",
    "        images = load_images(file, dpi=dpi, max_pages=max_pages)\n",
    "        file_hash = file_sha256(file)\n",
    "        for i, img in enumerate(images, 1):\n",
    "            pimg = preprocess_image(img)\n",
    "            lines = run_ocr(pimg)\n",
    "            text = '\\n'.join([line['text'] for line in lines])\n",
    "            lang = detect_language(text)\n",
    "            detections, boxes = collect_pii(lines)\n",
    "            redacted = apply_redactions(pimg.copy(), boxes)\n",
    "            save_page(redacted, file, i)\n",
    "            append_report({\n",
    "                'file': str(file),\n",
    "                'file_hash': file_hash,\n",
    "                'page': i,\n",
    "                'language': lang,\n",
    "                'detections': detections,\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11_benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: implement benchmarking on synthetic samples\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}